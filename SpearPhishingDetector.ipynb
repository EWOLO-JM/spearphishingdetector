{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyM0dOerKPSB/X/28XnwlV+E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EWOLO-JM/spearphishingdetector/blob/main/SpearPhishingDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anticipation des statégies d'hameçonnage par email par les techniques de IA(ML, DL et NLP)**"
      ],
      "metadata": {
        "id": "7L_OsUxejWfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Bibliotheques Python nécessaire et configuration initiale\n",
        "\n",
        "'''\n",
        "\n",
        "#  Libreries python nécessaire\n",
        "from colorama import Fore, Back, Style\n",
        "import colorama\n",
        "form colorama import Fore, Style,Back\n",
        "colorama.init()\n",
        "import re, os, sys\n",
        "from bs4 import BeautifulSoup\n",
        "import pprint\n",
        "from urlparse import urlparse\n",
        "import email\n",
        "from IPy import IP\n",
        "import email.header\n",
        "import csv\n",
        "from collections import Counter\n",
        "from pandas as pd\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "\n",
        "# Definition de l'encodage à l'UTF-8 et imprimer la sortie sur Jupiter Notebook\n",
        "\n",
        "stdout = sys.stdout\n",
        "reloard(sys)\n",
        "sys.setdefaultencoding('UTF8')\n",
        "sys.stdout = stdout\n",
        "\n",
        "'''\n",
        "Fonction de pré-traitement supplémentaires\n",
        "\n",
        "'''\n",
        "# EWOLO\n",
        "print(Fore.MAGENTA)\n",
        "print(Back.YELLOW)\n",
        "print(30 * \"*\" + \"SpearPhishingDetector\" + 30 * \"*\")\n",
        "print(Style.RESET_ALL)\n",
        "\n",
        "test_path = input(Fore.BLUE + \"Entrez le chemin du dossier où se trouve le courrier : \")\n",
        "\n",
        "\n",
        "# Difference entre deux listes\n",
        "\n",
        "def difference(first, second):\n",
        "  second = set(second)\n",
        "  for item in first:\n",
        "    first.remove(item)\n",
        "  return first\n",
        "\n",
        "# Compte le nombre de caractere dans une chaine donnée\n",
        "\n",
        "def count_characters(string):\n",
        "  return len(string) - string.count(' ') - string.count('\\n')\n",
        "\n",
        "# Extrait une URL dans le corps du message\n",
        "\n",
        "def extract_urls(msg):\n",
        "  mail = str(msg)\n",
        "  urls = re.findall(r\"http[s]?://(?://([a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", mail)\n",
        "  return urls\n",
        "\n",
        "# Extraire les urls d'encrage dans le message\n",
        "\n",
        "def extract_achor_urls(msg):\n",
        "  anchor_urls =[]\n",
        "  soup = BeautifulSoup(msg, 'html.parser')\n",
        "  for link in soup.findAll('a', attrs={'href': re.compile(\"^http[s]?://\")}):\n",
        "    anchor_urls.append(link.get('href'))\n",
        "  return anchor_urls\n",
        "\n",
        "# Extraire le domaine de l'émail\n",
        "\n",
        "def get_email_domain(strings):\n",
        "  domain = re.search(\"@[\\w.]+\", string)\n",
        "  if domain is None:\n",
        "    return None\n",
        "  return str(domaine.group())[1:]\n",
        "\n",
        "# Extraine le domaine de l'url\n",
        "\n",
        "def get_url_domain(url):\n",
        "  domain = None\n",
        "  if url:\n",
        "    if u'@' in str(url):\n",
        "      domain = get_email_domain(str(url))\n",
        "    else:\n",
        "      parsed_uri = urlparse(url)\n",
        "      domain = '{uri.netloc}'.format(uri=parsed_uri)\n",
        "      if domain.startwith(\"www.\"):\n",
        "        return domain[4:]\n",
        "  return domain\n",
        "\n",
        "\n",
        "# Trouver l'url la pus frequente dans une liste d'URLs\n",
        "\n",
        "def most_common_url(urls):\n",
        "  if urls:\n",
        "    modal_url = max(set(urls), key = urls.count)\n",
        "    return modal_url\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "# Supprimer le fichier s'il existe\n",
        "\n",
        "def remove_if_exists(filename):\n",
        "  try:\n",
        "    os.remove(filename):\n",
        "    except OSError:\n",
        "      pass\n",
        "\n",
        "'''\n",
        "Functions needed to extract the necessary fields\n",
        "\n",
        "'''\n",
        "# Get paths to spam, test, easy_ham, phishing_2015 and phishing_2016 folders\n",
        "#spam_path = \"C:/Users/FENNY/Desktop/ML-Case Study/spamassasin/New folder/OWN/dataset/spam\"\n",
        "#test_path = \"C:/Users/FENNY/Desktop/BE-Final/SPAM-ASSA/dataset/\"\n",
        "#ham_path = \"C:/Users/FENNY/Desktop/ML-Case Study/spamassasin/New folder/OWN/dataset/easy_ham\"\n",
        "#phishing_2015_path = \"C:/Users/FENNY/Desktop/ML-Case Study/spamassasin/New folder/OWN/dataset/mbox/phishing_2015\"\n",
        "#phishing_2016_path = \"C:/Users/FENNY/Desktop/ML-Case Study/spamassasin/New folder/OWN/dataset/mbox/phishing_2016\"\n",
        "\n",
        "\n",
        "# Lire les fichiers (nom de fichiers) dans le chemin choisi\n",
        "\n",
        "def get_files(path):\n",
        "  mail_files(path):\n",
        "  mail_files = os.listdir(path)\n",
        "  return mail_files\n",
        "\n",
        "# Extraire le message de l'email(lu commeune chaine)\n",
        "\n",
        "def extract_msg(path, mail_file):\n",
        "  mail_file = path + '/' + mail_file\n",
        "  fh = open(mail_file, \"rb\")\n",
        "  mail = fp.read()\n",
        "  fp.close()\n",
        "\n",
        "  msg = email.message_from_string(mail)\n",
        "  return msg\n",
        "\n",
        "# Extraire le corps du message\n",
        "\n",
        "def extract_body(msg):\n",
        "  body_content = \"\"\n",
        "  if msg.is_multipart():\n",
        "    for payloard in msg.get_payloard():\n",
        "    body_content += str(payloard.get_payloard())\n",
        "  else:\n",
        "    body_content += msg.get_payloard()\n",
        "  return body_content\n",
        "\n",
        "# Extraire le sujet du message\n",
        "\n",
        "def extract_subj(msg):\n",
        "  decode_subj = email.header(msg['Subject'])[0]\n",
        "  try:\n",
        "    suj_content = unicode(decode_subj[0])\n",
        "  except:\n",
        "    subj_content = \"None\"\n",
        "  return subj_content\n",
        "\n",
        "# Extraire l'adresse de l'expéditeur du méssage\n",
        "\n",
        "def extract_send_address(msg):\n",
        "  decode_send = email.header(msg['From'])[0]\n",
        "  try:\n",
        "    send_adress = unicode(decode_send[O])\n",
        "  except:\n",
        "      send_address = \"None\"\n",
        "  return send_address\n",
        "\n",
        "# Extraire l'url modale du message\n",
        "\n",
        "def extract_modal_url(msg):\n",
        "  urls = extract_urls(msg)\n",
        "  modal_url = most_common_url(urls)\n",
        "  return modal_url\n",
        "\n",
        "# Extraire tous les liens\n",
        "\n",
        "def extract_all_links(msg):\n",
        "  links = []\n",
        "  soup = BeautifulSoup(msg, 'html.parser')\n",
        "  for link in soup.finAll('a'):\n",
        "    links.append(link.get('href'))\n",
        "\n",
        "  all_urls = extract_urls(msg)\n",
        "  anchor_urls = extract_anchor_urls(msg)\n",
        "\n",
        "  urls = difference(all_urls, anchor_urls)\n",
        "  links = links = urls\n",
        "  return links\n",
        "\n",
        "  '''\n",
        "\n",
        "  Extraction des champs nécessaires\n",
        "\n",
        "  '''\n",
        "\n",
        "# Exécutez la fonction pour extraire les champs nécessaires d'un dossier\n",
        "\n",
        "def extract_necessary_fields(path, mail):\n",
        "  necessary_fields = {}\n",
        "  msg = extract_msg(path, mail):\n",
        "  necessary_fields = {}\n",
        "  msg = extract_msg(path, mail)\n",
        "\n",
        "  necessary_fields['body'] = extract_body(msg)\n",
        "  necessary_fields['subj'] = extract_subj(msg)\n",
        "  necessary_fields['send'] = extract_send_address(msg)\n",
        "  necessary_fields['replyTo'] = extract_replyTo_address(msg)\n",
        "  necessary_fields['modalURL'] = extract_modal_url(msg)\n",
        "  necessary_fields['links'] = extract_all_links(msg)\n",
        "\n",
        "  return necessary_fields\n",
        "\n",
        "\n",
        "#  Verifions que tous ce qui a été faite jusqu'ici est coorrecte\n",
        "\n",
        "'''\n",
        "Fonctions our extraire les attributs basés sur le corps\n",
        "\n",
        "'''\n",
        "\n",
        "# Booléen : si le code HTML est présent ou pas\n",
        "\n",
        "def body_html(body_content):\n",
        "  body_html = bool(BeautifulSoup(body_content, \"html.parser\").find(\"form\"))\n",
        "  return body_forms\n",
        "\n",
        "# Entier : nombre de mot dans le corps\n",
        "\n",
        "def body_noWords(body_content):\n",
        "  body_noWords = len(body_content.split())\n",
        "  return body_noWords\n",
        "\n",
        "# Entier : nombre de caractere dans le corps\n",
        "\n",
        "def body_noCharacters(body_content):\n",
        "  body_noCharacters = count_characters(body_content)\n",
        "  return body_noCharacters\n",
        "\n",
        "# Entier : Nombre de mots distints dans le corps du texte\n",
        "\n",
        "def body_noDistinctWords(body_content):\n",
        "  body_noDistinctWords = len(Counter(body_content.split()))\n",
        "  return body_noDistinctWords\n",
        "\n",
        "# Flottant : richesse du texte(corps)\n",
        "\n",
        "def body_richness(body_noWords, body_noCharacters):\n",
        "  try:\n",
        "    body_richness = float(body_noWords)/body_noCharacters\n",
        "  except:\n",
        "    body_richness = 0\n",
        "  return body_richness\n",
        "\n",
        "# Entier : Nombre de mots de fonction dans le corps\n",
        "\n",
        "def body_noFunctionWords(body_content):\n",
        "  body_noFunctionWords = 0\n",
        "  wordList = re.sub(\"^A-Za-z\", \"\", body_content.strip()).lower().split()\n",
        "  function_words = [\"account\", \"access\", \"bank\",\"credit\", \"click\", \"identity\", \"inconvenience\", \"information\", \"limited\", \"log\", \"minutes\", \"password\", \"recently\", \"risk\", \"social\", \"security\", \"service\", \"suspended\"]\n",
        "  for word in function_words:\n",
        "    body_noFunctionWords += wordlist.count(word)\n",
        "  return body_noFunctionWords\n",
        "\n",
        "# Booléen : Si le corps contient ou non le mot \"suspenssion\"\n",
        "\n",
        "def body_suspension(body_content):\n",
        "  body_suspension = \"suspension\" in body_content.lower()\n",
        "  return body_suspension\n",
        "\n",
        "# Booléen : si le corps contient ou non la phrase \"verifier votre compte\"\n",
        "\n",
        "def body_verifyYourAccount(body_content):\n",
        "  phrase = \"verifyyouraccount\"\n",
        "  content = re.sub(r\"[^A-Za-z]\", \"\", body_content.strip()).lower()\n",
        "  body_verifyYourAccount = phrase in content\n",
        "  return body_verifyYourAccount\n",
        "\n",
        "def extract_body_attributes(body_content):\n",
        "  body_attributes = {}\n",
        "\n",
        "  body_attributes['body_html'] = body_html(body_content)\n",
        "  body_attributes['body_forms'] = body_forms(body_content)\n",
        "  body_attributes['body_noWords'] = body_html(body_content)\n",
        "  body_attributes['body_html'] = body_noWords(body_content)\n",
        "  body_attributes['body_noCharacters'] = body_noCharacters(body_content)\n",
        "  body_attributes['body_richness'] = body_html(body_attributes['body_noWords'], body_attributes['body_noCharacters'])\n",
        "  body_attributes['body_noFunctionWords'] = body_noFunctionWords(body_content)\n",
        "  body_attributes['body_suspension'] = body_suspension(body_content)\n",
        "  body_attributes['body_verifyYourAccount'] = body_verifyYourAccount(body_content)\n",
        "\n",
        "  return body_attributes\n",
        "\n",
        "  '''\n",
        "Fonctions d'extraction des attributs de la ligne d'objet\n",
        "\n",
        "'''\n",
        "\n",
        "# Booléen : Verifier si le courrier est une reponse a un courrier precendent\n",
        "\n",
        "def subj_reply(subj_content):\n",
        "  subj_reply = subj_content.lower().startswith(\"re:\")\n",
        "  return subj_reply\n",
        "\n",
        "# Bouleen : vérifier si le courrier est une redurection d'un autre courriel\n",
        "\n",
        "def subj_forward(subj_content):\n",
        "  subj_forward = subj_content.lower().startswith(\"fwd:\")\n",
        "  return subj_forward\n",
        "\n",
        "# Entier : nombre de mot dans le sujet\n",
        "\n",
        "def subj_noWords(subj_content):\n",
        "  subj_noWords = len(subj_content.split())\n",
        "  return subj_noWords\n",
        "\n",
        "# Entier : nombre de caracteres dans le sujet\n",
        "\n",
        "def subj_noCharacters(subj_content):\n",
        "  subj_noCharacters = count_characters(subj_content)\n",
        "  return subj_noCharacters\n",
        "\n",
        "# Flottant : richesse du texte (sujet)\n",
        "\n",
        "def subj_richness(subj_noWords, subj_noCharacters):\n",
        "  try:\n",
        "    subj_richness = float(subj_noWords)/subj_noCharacters\n",
        "  except:\n",
        "    subj_richness = 0\n",
        "  return subj_richness\n",
        "\n",
        "# Booleen : Si le sujet contient le mot \"vérifier\" ou non\n",
        "\n",
        "def subj_verify(subj_content):\n",
        "  subj_verify = \"verify\" in subj_content.lower()\n",
        "  return subj_verify\n",
        "\n",
        "# Booleen : si le sujet contient ou non le mot \"debit\"\n",
        "\n",
        "def subj_debit(subj_content):\n",
        "  subj_debit = \"debit\" in subj_content.lower()\n",
        "  return subj_debit\n",
        "\n",
        "# Booleen : Si le sujet contient ou non le mot \"banque\"\n",
        "\n",
        "def subj_bank(subj_content):\n",
        "  subj_bank = \"bank\" in subj_content.lower()\n",
        "  return subj_bank\n",
        "\n",
        "\n",
        "def extract_subj_attributes(subj_content):\n",
        "  subj_attributes(subj_content):\n",
        "  subj_attributes = {}\n",
        "\n",
        "  subj_attributes['subj_reply'] = subj_reply(subj_content)\n",
        "  subj_attributes['subj_forward'] = subj_forward(subj_content)\n",
        "  subj_attributes['subj_noWords'] = subj_noWords(subj_content)\n",
        "  subj_attributes['subj_noCharacters'] = subj_noCharacters(subj_content)\n",
        "  subj_attributes['subj_richness'] = subj_richness(subj_content)\n",
        "  subj_attributes['subj_verify'] = subj_verify(subj_content)\n",
        "  subj_attributes['subj_debit'] = subj_debit(subj_content)\n",
        "  subj_attributes['subj_bank'] = subj_bank(subj_content)\n",
        "\n",
        "  return subj_attributes\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Fonctions d'extraction des attributs basés sur l'adresse de l'expéditeur\n",
        "\n",
        "'''\n",
        "\n",
        "# Entier : nombre de mots dans l'adresse de l'expédditeur\n",
        "\n",
        "def send_noWords(send_address):\n",
        "  send_noWords = len(send_address.split())\n",
        "  return send_noWords\n",
        "\n",
        "# Entier : Nombre de caracteres dans l'adresse de l'expéditeur\n",
        "\n",
        "def send_noCharacters(send_address):\n",
        "  send_noCharacters = count_characters(send_address)\n",
        "  return send_noCharacters\n",
        "\n",
        "# Booleen : Verifier si les domaines de l'expediteur et du destinataire de la reponse sont different\n",
        "\n",
        "def send_diffSendReplyTo(send_address, replyTo_address):\n",
        "  send_diffSendReplyTo = get_email_domain(send_address)\n",
        "  replyTo_domain = get_email_domain(replyTo_address)\n",
        "\n",
        "  send_diffSenderReplyTo = False\n",
        "  if replyTo_address != \"None\":\n",
        "    send_diffSenderReplyTo = (send_domain != replyTo_domain)\n",
        "  return send_diffSenderReplyTo\n",
        "\n",
        "# Booleen : Verifie si le domaine modal de l'expéditeur et celui de l'email sont differnts\n",
        "\n",
        "def send_nonModalSenderDomain(send_address, modal_url):\n",
        "  send_domain = get_email_domain(send_address)\n",
        "  modal_domain = get_url_domain(modal_url)\n",
        "\n",
        "  send_nonModalSenderDomain = False\n",
        "  if str(modal_url) != \"None\":\n",
        "    send_nonModalSenderDomain = (send_domain != modal_url)\n",
        "  return send_nonModalSenderDomain\n",
        "\n",
        "  def extract_send_attributes(send_address, replyTo_address, modal_url):\n",
        "    send_attributes = {}\n",
        "\n",
        "    send_attributes['send_noWords'] = send_noWords(send_address)\n",
        "    send_attributes['send_noCharacters'] = send_noCharacters(send_address)\n",
        "    send_attributes['send_diffSenderReplyTo'] = send_diffSenderReplyTo(send_address)\n",
        "    send_attributes['send_nonModalSenderDomain'] = send_nonModalSenderDomain(send_address)\n",
        "\n",
        "    return send_attributes\n",
        "\n",
        "    '''\n",
        "    Fonctions d'extraction d'attributs basés sur l'URL\n",
        "\n",
        "    '''\n",
        "\n",
        "# Bouleen : Si l'on utilse les adress IP plutot que les noms de domaine\n",
        "\n",
        "def url_iAddress(links_list):\n",
        "  url_ipAddress = False\n",
        "  for link in links_list:\n",
        "    link_address = get_url_domain(link)\n",
        "    if \":\" in str(link_address):\n",
        "      link_address = link_address[:link_address.index(\":\")]\n",
        "    try:\n",
        "      IP(link_address)\n",
        "      url_ipAddress = True\n",
        "      break\n",
        "    except:\n",
        "      continue\n",
        "  return url_ipAddress\n",
        "\n",
        "# Entier : nombre de liens dans un courriel qui contiennent des address IP\n",
        "\n",
        "def url_noIpAddresses(links_list):\n",
        "  url_noIPAddresses = 0\n",
        "  for link in links_list:\n",
        "    link_address = get_url_domain(link)\n",
        "    if \":\" in str(link_address):\n",
        "      link_address = link_address[:link_address.index(\":\")]\n",
        "    try:\n",
        "      IP(link_address)\n",
        "      url_noIpAddress = url_noIpAddresses + 1\n",
        "      break\n",
        "    except:\n",
        "      continue\n",
        "  return url_noIpAddresses\n",
        "\n",
        "# Booleen : Si le symbole \"@\" est présent dans une url\n",
        "\n",
        "def url_atSymbol(links_list):\n",
        "  url_atSymbol = False\n",
        "  for link in links_url:\n",
        "    if u'@' in str(link):\n",
        "      url_atSymbol = True\n",
        "      break\n",
        "  return url_atSymbol\n",
        "\n",
        "# Entier : nombre de liens dans le corps du message\n",
        "\n",
        "def url_noLinks(links_list):\n",
        "  url_noLinks = len(links_list)\n",
        "  return url_noLinks\n",
        "\n",
        "\n",
        "# Entier : Nombre de liens externes dans le corps du message\n",
        "\n",
        "def url_noExtLinks(body_content):\n",
        "  url_noExtLinks = len(extract_urls(body_content))\n",
        "  return url_noExtLinks\n",
        "\n",
        "# Entier : Nombre de liens internes dans le corps du message\n",
        "\n",
        "def url_noIntLinks(lonks_list, body_content):\n",
        "  url_noIntLinks = url_noLinks(links_list) - url_noExtLinks(body_content)\n",
        "  return url_noLinks\n",
        "\n",
        "# Entier : Nombre de kiens vers des images dans le corps du message\n",
        "\n",
        "def url_noLinks(body_content):\n",
        "  soup = BeautifulSoup(body_content)\n",
        "  images_links = soup.finAll('img')\n",
        "  return len(image_links)\n",
        "\n",
        "# Entier : Nombre de domaines URL dans le corps du message\n",
        "\n",
        "def url_noDomains(body_content, send_address, replyTo_address):\n",
        "  domains = set()\n",
        "  all_urls = extract_urls(body_content)\n",
        "  for url in all_urls:\n",
        "    domain = get_url_domain(url)\n",
        "    domains.add(get_email_domain(replyTo_address))\n",
        "    return len(domains)\n",
        "\n",
        "# Entier : Nombre de périodes dans le lien avec le plus grand nombre de périodes\n",
        "\n",
        "def url_maxNoPeriods(links_list):\n",
        "  max_periods = 0\n",
        "  for link in links_list:\n",
        "    num_periods = str(link).count('.')\n",
        "    if max_periodes < num_periods:\n",
        "      max_periods = num_periods\n",
        "  return max_periods\n",
        "\n",
        "# Booleen : vérifier si le texte du lien contient ds termes tels que \"cliquer\" \"ici\", \"se connecter\" ou \"mettre à jour\".\n",
        "\n",
        "def url_linkText(body_content):\n",
        "  url_linkText = False\n",
        "  linkText = ['click', 'here', 'login', 'update']\n",
        "  soup = BeautifulSoup(body_content)\n",
        "  for link in soup.findAll('a'):\n",
        "    if link.contents:\n",
        "      contents = list(re.sub(r'([^\\s\\w]|_)+', '', str(link.contents[0])).lower()split())\n",
        "      extra_contents = set(contents).difference(set(linkText_words))\n",
        "      if len(extra_contents) < len(contents):\n",
        "        url_linkText = True\n",
        "        break\n",
        "  return url_linkText\n",
        "\n",
        "# Booleen: S'il n'existe pas de lien dans le dimain modele  /if 'here' links don't map to modal domain\n",
        "def url_nonModalHereLinks(body_content, modal_url):\n",
        "    modal_domain = get_url_domain(modal_url)\n",
        "\n",
        "    url_nonModalHereLinks = False\n",
        "    if str(modal_url) != \"None\":\n",
        "        soup = BeautifulSoup(body_content)\n",
        "        for link in soup.findAll('a'):\n",
        "            if link.contents:\n",
        "                if \"here\" in link.contents[0]:\n",
        "                    link_ref = link.get('href')\n",
        "                    if get_url_domain(link_ref) != modal_domain:\n",
        "                        url_nonModalHereLinks = True\n",
        "                        break\n",
        "    return url_nonModalHereLinks\n",
        "\n",
        "# Booleen : Si l'URL accede a un autre port que le port 80\n",
        "def url_ports(links_list):\n",
        "    url_ports = False\n",
        "    for link in links_list:\n",
        "        link_address = get_url_domain(link)\n",
        "        if \":\" in str(link_address):\n",
        "            port = link_address[link_address.index(\":\"):][1:]\n",
        "            if str(port) != str(80):\n",
        "                url_ports = True\n",
        "                break\n",
        "    return url_ports\n",
        "\n",
        "\n",
        "# Entier : Nombre de liens avec information sur le port\n",
        "\n",
        "def url_noPorts(links_list):\n",
        "    url_noPorts = 0\n",
        "    for links in link_list:\n",
        "        link_address = get_url_domain(link)\n",
        "        if \":\" in str(link_address):\n",
        "            url_noPorts = url_noPorts + 1\n",
        "    return url_noPorts\n",
        "\n",
        "def extract_url_attributes(links_list, body_content, send_address, replyTo_address, modal_url):\n",
        "    url_attributes = {}\n",
        "\n",
        "    url_attributes['url_ipAddress'] = url_ipAddress(links_list)\n",
        "    url_attributes['url_noIpAddresses'] = url_noIpAddresses(links_list)\n",
        "    url_attributes['url_atSymbol'] = url_atSymbol(links_list)\n",
        "    url_attributes['url_noLinks'] = url_noLinks(links_list)\n",
        "    url_attributes['url_noExtLinks'] = url_noExtLinks(body_content)\n",
        "    url_attributes['url_noIntLinks'] = url_noIntLinks(links_list, body_content)\n",
        "    url_attributes['url_noImgLinks'] = url_noImgLinks(body_content)\n",
        "    url_attributes['url_noDomains'] = url_noDomains(body_content, send_address, replyTo_address)\n",
        "    url_attributes['url_maxNoPeriods'] = url_maxNoPeriods(links_list)\n",
        "    url_attributes['url_linkText'] = url_linkText(body_content)\n",
        "    url_attributes['url_nonModalHereLinks'] = url_ipAddress(body_content, modal_url)\n",
        "    url_attributes['url_ports'] = url_ipAddress(links_list)\n",
        "    url_attributes['url_noPorts'] = url_ipAddress(links_list)\n",
        "\n",
        "    return url_attributes\n",
        "\n",
        "'''\n",
        "\n",
        "FONCTION POUR EXRAIRE LE SCRIPT A BASE DES ATTRIBUTS\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# Booleen : si les scripts sont present dans le corps du mail\n",
        "\n",
        "def script_scripts(body_content):\n",
        "    script_scripts = bool(BeautifulSoup(body_content, \"html.parser\").find(\"script\"))\n",
        "    return script_scripts\n",
        "\n",
        "# Booleen : Si le script present est en javascript\n",
        "\n",
        "def script_javaScript(body_content):\n",
        "    script_javaScript = False\n",
        "    if script_scripts(body_content):\n",
        "        soup = BeautifulSoup(body_content)\n",
        "        for script in soup.findAll('script'):\n",
        "            if script.get('type') == \"text/javascript\":\n",
        "                script_javaScript = True\n",
        "    return script_javaScript\n",
        "\n",
        "# Booleen : ooléen : vérifie si le script remplace la barre d'état dans le client de messagerie.\n",
        "\n",
        "def script_statusChange(body_content):\n",
        "    script_statusChange = False\n",
        "    if script_scripts(body_content):\n",
        "        soup = BeautifulSoup(body_content)\n",
        "        for script in soup.findAll('script'):\n",
        "            if \"window.status\" in str(script.contents):\n",
        "                script_statusChange = True\n",
        "    return script_statusChange\n",
        "\n",
        "# Verifier si le mail contient une fenetre pop-up\n",
        "\n",
        "def script_popups(body_content):\n",
        "    script_popups = False\n",
        "    if script_scripts(body_content):\n",
        "        soup = BeautifuSoup(body_content)\n",
        "        for script in soup.findAll('script.contents'):\n",
        "            if \"window.open\" in str(script.contents):\n",
        "                script_popups = True\n",
        "    return script_popups\n",
        "\n",
        "# Entier : Nombre d'événements \"on-click\" (sur le clic)\n",
        "\n",
        "def scriptnoOnClickEvents(body_content):\n",
        "    scriptnoOnClickEvents = 0\n",
        "    if script_scripts(body_content):\n",
        "        soup = BeautifulSoup(body_content)\n",
        "        codes = soup.findAll('button',{\"onclick\":True})\n",
        "        script_noOnClickEvents = len(codes)\n",
        "    return script_noOnClickEvents\n",
        "\n",
        "# Boleen : Si le javascript provient de l'extérieur du domaine modal\n",
        "\n",
        "def script_nonModalJsLoards(body_content):\n",
        "  script_nonModalJsLoards = False\n",
        "if script_scripts(body_content):\n",
        "    if str(modal_url) != \"None\":\n",
        "        soup = BeautifulSoup(body_content)\n",
        "        for script in soup.findAll('script'):\n",
        "            source = is not None:\n",
        "            if get_url_domain(source) != modal_domain:\n",
        "                    script_nonModalJsLoards = True\n",
        "                    break\n",
        "    return script_nonModalJsLoards\n",
        "\n",
        "def extract_script_attributes(body_content, modal_url):\n",
        "    script_attributes = {}\n",
        "\n",
        "    script_attributes['script_scripts'] = script_scripts(body_content)\n",
        "    script_attributes['script_javaScripts'] = script_javaScripts(body_content)\n",
        "    script_attributes['script_statusChange'] = script_statusChange(body_content)\n",
        "    script_attributes['script_popups'] = script_popups(body_content)\n",
        "    script_attributes['scriptnoOnClickEvents'] = scriptnoOnClickEvents(body_content)\n",
        "    script_attributes['script_nonModalJsLoards'] = script_nonModalJsLoards(body_content, modal_url)\n",
        "\n",
        "    return script_attributes\n",
        "#test_path = \"C:/Users/FENNY/Desktop:BE-Final:SPAM-ASSA:dataset/demo/\"\n",
        "mail_files = get_files(test_path)\n",
        "#print len(mail_files)\n",
        "#print mail_files[0]\n",
        "mailOneccessary_fields = extract_neccessary_fieds(test_path, mail_files[0])\n",
        "#pprint.pprint(mailOneccessary_fields, width = 1)\n",
        "\n",
        "'''\n",
        "\n",
        "Overall feature extraction (40 features)\n",
        "\n",
        "'''\n",
        "\n",
        "def overall_feature_extraction(path, label, mail):\n",
        "    necessary_fields = extract_necessary_fields(path, mail)\n",
        "\n",
        "    body_attributes = extract_body_attributes(necessary_fields['body'])\n",
        "    subj_attributes = extract_subj_attributes(necessary_fields['subj'])\n",
        "    send_attributes = extract_send_attributes(necessary_fields['send'], necessary_fields['replyTO'], necessary_fields['modalURL'])\n",
        "    url_attributes = extract_url_attributes(necessary_fields['links'], necessary_fields['body'], necessary_fields['send'], necessary_fields['replyTO'], necessary_fields['modalURL'])\n",
        "    script_attributes = extract_script_attributes(necessary_fields['send'], necessary_fields['body'], necessary_fields['modalURL'])\n",
        "\n",
        "\n",
        "    feautures = body_attributes\n",
        "    fefeautures.update(subj_attributes)\n",
        "    fefeautures.update(send_attributes)\n",
        "    fefeautures.update(url_attributes)\n",
        "    fefeautures.update(script_attributes)\n",
        "    feautures['label'] = label\n",
        "\n",
        "    return feautures\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SPoIKf5prT-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "FYLWDeLW9wOS"
      }
    }
  ]
}